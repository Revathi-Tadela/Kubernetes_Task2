[ec2-user@ip-172-31-35-237 ~]$ sudo yum install aws-cli -y
Last metadata expiration check: 0:22:01 ago on Sat Sep 21 09:34:28 2024.
Package awscli-2-2.15.30-1.amzn2023.0.1.noarch is already installed.
Dependencies resolved.
Nothing to do.
Complete!
[ec2-user@ip-172-31-35-237 ~]$ aws configure
AWS Access Key ID [None]: ^C
[ec2-user@ip-172-31-35-237 ~]$ aws configure
AWS Access Key ID [None]: AKIA2UC3B477EHC6IFWU
AWS Secret Access Key [None]: 
Default region name [None]: us-east-1
Default output format [None]: json
[ec2-user@ip-172-31-35-237 ~]$ aws sts get-caller-identity
{
    "UserId": "AIDA2UC3B477DYFUA2KJU",
    "Account": "730335406078",
    "Arn": "arn:aws:iam::730335406078:user/eks-admin"
}
[ec2-user@ip-172-31-35-237 ~]$ curl --silent --location "https://github.com/weaveworks/eksctl/releases/download/latest_release/eksctl_$(uname -s)_amd64.tar.gz" | tar xz -C /tmp

gzip: stdin: not in gzip format
tar: Child returned status 1
tar: Error is not recoverable: exiting now
[ec2-user@ip-172-31-35-237 ~]$ curl --silent --location "https://github.com/weaveworks/eksctl/releases/latest/download/eksctl_Linux_amd64.tar.gz" | tar xz -C /tmp 
[ec2-user@ip-172-31-35-237 ~]$ cd /tmp
[ec2-user@ip-172-31-35-237 tmp]$ ls -lrt
total 140112
-rwxr-xr-x. 1 ec2-user ec2-user 143462400 Sep  4 11:12 eksctl
drwx------. 3 root     root            60 Sep 21 09:43 systemd-private-226489dee6a44edfbfee6d85fd310cf5-systemd-resolved.service-M3hjEA
drwx------. 3 root     root            60 Sep 21 09:43 systemd-private-226489dee6a44edfbfee6d85fd310cf5-dbus-broker.service-WJ9yFP
drwx------. 3 root     root            60 Sep 21 09:43 systemd-private-226489dee6a44edfbfee6d85fd310cf5-policy-routes@enX0.service-9V3nRy
drwx------. 3 root     root            60 Sep 21 09:43 systemd-private-226489dee6a44edfbfee6d85fd310cf5-systemd-logind.service-zRYu9U
drwx------. 3 root     root            60 Sep 21 09:43 systemd-private-226489dee6a44edfbfee6d85fd310cf5-chronyd.service-NfBuH6
-rw-------. 1 ec2-user ec2-user         0 Sep 21 09:45 juju-mk69bd8dc7d2764264cc5a3f0a64dd12f700bbe1
-rw-------. 1 ec2-user ec2-user         0 Sep 21 09:45 juju-mkd0264cab96b8158ea147e8e92a5ca2fc201f4b
-rw-------. 1 ec2-user ec2-user         0 Sep 21 09:45 juju-mk5f377c42c55cd70f48bdaa1ac96608178ba470
-rw-------. 1 ec2-user ec2-user         0 Sep 21 09:45 juju-mke39e9c84c97a4cc79f46eddd6372cb206cf268
-rw-------. 1 ec2-user ec2-user         0 Sep 21 09:45 juju-mk0c05d4d080b7cdfc65fc61ffc33c56f44f92e6
-rw-------. 1 ec2-user ec2-user         0 Sep 21 09:45 juju-mk133e77b266bb33c494116c3054e2c2f1375135
-rw-------. 1 ec2-user ec2-user         0 Sep 21 09:45 juju-mkb08f59e516b0d424ad13a91ccb2dacf7c7277f
-rw-------. 1 ec2-user ec2-user         0 Sep 21 09:45 juju-mk23eace0344495582ff3ffc34ef64c5e2823c0b
-rw-------. 1 ec2-user ec2-user         0 Sep 21 09:45 juju-mk9a8c725ee9c1b19a2220eb76ac32d84e5f9db3
-rw-------. 1 ec2-user ec2-user         0 Sep 21 09:45 juju-mk48b97e177eed8b45b2497b4a5355eb8b10afbe
-rw-------. 1 ec2-user ec2-user         0 Sep 21 09:45 juju-mk88f1e613013ac73655cb16d65fe871e5b8acbf
-rw-------. 1 ec2-user ec2-user         0 Sep 21 09:45 juju-mk31d488c08ab9e06d36b37d93edbcda9c61de3f
-rw-------. 1 ec2-user ec2-user         0 Sep 21 09:45 juju-mkef9aaff15d283d6b97d136c6699af16b09f318
-rw-------. 1 ec2-user ec2-user         0 Sep 21 09:45 juju-mkbb355815a506add29c5d0b6b99541b24ddfbb9
-rw-------. 1 ec2-user ec2-user         0 Sep 21 09:45 juju-mkf0813785b02e8c2f81710723758be1ce3495c7
-rw-------. 1 ec2-user ec2-user         0 Sep 21 09:45 juju-mk6371d46da52852a10e5d36c47a6130f62459d0
-rw-------. 1 ec2-user ec2-user         0 Sep 21 09:46 juju-mk9bab7919fc13e4b960d13c91e47d3fae6c575e
-rw-------. 1 ec2-user ec2-user         0 Sep 21 09:46 juju-mk1d30f2bcdedcd5224458206a60e0bb002d6810
-rw-r--r--. 1 ec2-user ec2-user       193 Sep 21 09:46 minikube_status_85d757c40b021391bff41828f62cc0171dd27151_0.log
-rw-r--r--. 1 ec2-user ec2-user      4354 Sep 21 09:49 minikube_stop_aa33c8595bb20b3bfadd1ca1ca2e179d4f84c832_0.log
[ec2-user@ip-172-31-35-237 tmp]$ cd eksctl
-bash: cd: eksctl: Not a directory
[ec2-user@ip-172-31-35-237 tmp]$ sudo mv /tmp/eksctl /usr/local/bin
[ec2-user@ip-172-31-35-237 tmp]$ eksctl version
0.190.0
[ec2-user@ip-172-31-35-237 tmp]$ curl -LO "https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl"
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
100   138  100   138    0     0   2263      0 --:--:-- --:--:-- --:--:--  2300
100 53.7M  100 53.7M    0     0  75.1M      0 --:--:-- --:--:-- --:--:-- 72.1M
[ec2-user@ip-172-31-35-237 tmp]$ sudo install -o root -g root -m 0755 kubectl /usr/local/bin/kubectl
[ec2-user@ip-172-31-35-237 tmp]$ eksctl create cluster \
--name my-cluster \
--region us-east-1 \
--nodegroup-name linux-nodes \
--node-type t3.medium \
--nodes 2 \
--nodes-min 2 \
--nodes-max 4 \
--managed
2024-09-21 10:10:46 [ℹ]  eksctl version 0.190.0
2024-09-21 10:10:46 [ℹ]  using region us-east-1
2024-09-21 10:10:46 [ℹ]  setting availability zones to [us-east-1b us-east-1a]
2024-09-21 10:10:46 [ℹ]  subnets for us-east-1b - public:192.168.0.0/19 private:192.168.64.0/19
2024-09-21 10:10:46 [ℹ]  subnets for us-east-1a - public:192.168.32.0/19 private:192.168.96.0/19
2024-09-21 10:10:46 [ℹ]  nodegroup "linux-nodes" will use "" [AmazonLinux2/1.30]
2024-09-21 10:10:46 [ℹ]  using Kubernetes version 1.30
2024-09-21 10:10:46 [ℹ]  creating EKS cluster "my-cluster" in "us-east-1" region with managed nodes
2024-09-21 10:10:46 [ℹ]  will create 2 separate CloudFormation stacks for cluster itself and the initial managed nodegroup
2024-09-21 10:10:46 [ℹ]  if you encounter any issues, check CloudFormation console or try 'eksctl utils describe-stacks --region=us-east-1 --cluster=my-cluster'
2024-09-21 10:10:46 [ℹ]  Kubernetes API endpoint access will use default of {publicAccess=true, privateAccess=false} for cluster "my-cluster" in "us-east-1"
2024-09-21 10:10:46 [ℹ]  CloudWatch logging will not be enabled for cluster "my-cluster" in "us-east-1"
2024-09-21 10:10:46 [ℹ]  you can enable it with 'eksctl utils update-cluster-logging --enable-types={SPECIFY-YOUR-LOG-TYPES-HERE (e.g. all)} --region=us-east-1 --cluster=my-cluster'
2024-09-21 10:10:46 [ℹ]  default addons vpc-cni, kube-proxy, coredns were not specified, will install them as EKS addons
2024-09-21 10:10:46 [ℹ]  
2 sequential tasks: { create cluster control plane "my-cluster", 
    2 sequential sub-tasks: { 
        2 sequential sub-tasks: { 
            1 task: { create addons },
            wait for control plane to become ready,
        },
        create managed nodegroup "linux-nodes",
    } 
}
2024-09-21 10:10:46 [ℹ]  building cluster stack "eksctl-my-cluster-cluster"
2024-09-21 10:10:46 [ℹ]  deploying stack "eksctl-my-cluster-cluster"
2024-09-21 10:11:16 [ℹ]  waiting for CloudFormation stack "eksctl-my-cluster-cluster"
2024-09-21 10:11:46 [ℹ]  waiting for CloudFormation stack "eksctl-my-cluster-cluster"
2024-09-21 10:12:46 [ℹ]  waiting for CloudFormation stack "eksctl-my-cluster-cluster"
2024-09-21 10:13:46 [ℹ]  waiting for CloudFormation stack "eksctl-my-cluster-cluster"
2024-09-21 10:14:46 [ℹ]  waiting for CloudFormation stack "eksctl-my-cluster-cluster"
2024-09-21 10:15:46 [ℹ]  waiting for CloudFormation stack "eksctl-my-cluster-cluster"
2024-09-21 10:16:46 [ℹ]  waiting for CloudFormation stack "eksctl-my-cluster-cluster"
2024-09-21 10:17:46 [ℹ]  waiting for CloudFormation stack "eksctl-my-cluster-cluster"
2024-09-21 10:18:46 [ℹ]  waiting for CloudFormation stack "eksctl-my-cluster-cluster"
2024-09-21 10:19:46 [ℹ]  waiting for CloudFormation stack "eksctl-my-cluster-cluster"
2024-09-21 10:20:46 [ℹ]  waiting for CloudFormation stack "eksctl-my-cluster-cluster"
2024-09-21 10:21:46 [ℹ]  waiting for CloudFormation stack "eksctl-my-cluster-cluster"
2024-09-21 10:21:47 [!]  recommended policies were found for "vpc-cni" addon, but since OIDC is disabled on the cluster, eksctl cannot configure the requested permissions; the recommended way to provide IAM permissions for "vpc-cni" addon is via pod identity associations; after addon creation is completed, add all recommended policies to the config file, under `addon.PodIdentityAssociations`, and run `eksctl update addon`
2024-09-21 10:21:47 [ℹ]  creating addon
2024-09-21 10:21:48 [ℹ]  successfully created addon
2024-09-21 10:21:48 [ℹ]  creating addon
2024-09-21 10:21:48 [ℹ]  successfully created addon
2024-09-21 10:21:49 [ℹ]  creating addon
2024-09-21 10:21:49 [ℹ]  successfully created addon
2024-09-21 10:23:49 [ℹ]  building managed nodegroup stack "eksctl-my-cluster-nodegroup-linux-nodes"
2024-09-21 10:23:49 [ℹ]  deploying stack "eksctl-my-cluster-nodegroup-linux-nodes"
2024-09-21 10:23:49 [ℹ]  waiting for CloudFormation stack "eksctl-my-cluster-nodegroup-linux-nodes"
2024-09-21 10:24:19 [ℹ]  waiting for CloudFormation stack "eksctl-my-cluster-nodegroup-linux-nodes"
2024-09-21 10:25:19 [ℹ]  waiting for CloudFormation stack "eksctl-my-cluster-nodegroup-linux-nodes"
2024-09-21 10:26:19 [ℹ]  waiting for CloudFormation stack "eksctl-my-cluster-nodegroup-linux-nodes"
2024-09-21 10:26:19 [ℹ]  waiting for the control plane to become ready
2024-09-21 10:26:19 [✔]  saved kubeconfig as "/home/ec2-user/.kube/config"
2024-09-21 10:26:19 [ℹ]  no tasks
2024-09-21 10:26:19 [✔]  all EKS cluster resources for "my-cluster" have been created
2024-09-21 10:26:19 [✔]  created 0 nodegroup(s) in cluster "my-cluster"
2024-09-21 10:26:19 [ℹ]  nodegroup "linux-nodes" has 2 node(s)
2024-09-21 10:26:19 [ℹ]  node "ip-192-168-21-167.ec2.internal" is ready
2024-09-21 10:26:19 [ℹ]  node "ip-192-168-52-115.ec2.internal" is ready
2024-09-21 10:26:19 [ℹ]  waiting for at least 2 node(s) to become ready in "linux-nodes"
2024-09-21 10:26:19 [ℹ]  nodegroup "linux-nodes" has 2 node(s)
2024-09-21 10:26:19 [ℹ]  node "ip-192-168-21-167.ec2.internal" is ready
2024-09-21 10:26:19 [ℹ]  node "ip-192-168-52-115.ec2.internal" is ready
2024-09-21 10:26:19 [✔]  created 1 managed nodegroup(s) in cluster "my-cluster"
2024-09-21 10:26:20 [ℹ]  kubectl command should work with "/home/ec2-user/.kube/config", try 'kubectl get nodes'
2024-09-21 10:26:20 [✔]  EKS cluster "my-cluster" in "us-east-1" region is ready
[ec2-user@ip-172-31-35-237 tmp]$ eksctl get cluster --name my-cluster
NAME            VERSION STATUS  CREATED                 VPC                     SUBNETS                                                                          SECURITYGROUPS           PROVIDER
my-cluster      1.30    ACTIVE  2024-09-21T10:11:10Z    vpc-0b6c5b1eb3b1f592c   subnet-0524f83a7edce250e,subnet-05e6a58afc33b3f9a,subnet-08f95d3c16eb993cf,subnet-0a0c84906050f549f       sg-07417bb13f9d54065    EKS
[ec2-user@ip-172-31-35-237 tmp]$ aws eks --region us-east-1 update-kubeconfig --name my-cluster
Added new context arn:aws:eks:us-east-1:730335406078:cluster/my-cluster to /home/ec2-user/.kube/config
[ec2-user@ip-172-31-35-237 tmp]$ kubectl get nodes
NAME                             STATUS   ROLES    AGE     VERSION
ip-192-168-21-167.ec2.internal   Ready    <none>   3m55s   v1.30.4-eks-a737599
ip-192-168-52-115.ec2.internal   Ready    <none>   3m52s   v1.30.4-eks-a737599
[ec2-user@ip-172-31-35-237 tmp]$ kubectl create deployment nginx --image=nginx
deployment.apps/nginx created
[ec2-user@ip-172-31-35-237 tmp]$ kubectl get deployments
NAME    READY   UP-TO-DATE   AVAILABLE   AGE
nginx   1/1     1            1           11s
[ec2-user@ip-172-31-35-237 tmp]$ kubectl expose deployment nginx --type=LoadBalancer --name=nginx-service --port=80 --target-port=80
service/nginx-service exposed
[ec2-user@ip-172-31-35-237 tmp]$ kubectl get service nginx-service
NAME            TYPE           CLUSTER-IP     EXTERNAL-IP                                                               PORT(S)        AGE
nginx-service   LoadBalancer   10.100.52.85   a232773891bec484daa25236523483fe-1363810085.us-east-1.elb.amazonaws.com   80:32547/TCP   22s
[ec2-user@ip-172-31-35-237 tmp]$ kubectl delete service nginx-service
service "nginx-service" deleted
[ec2-user@ip-172-31-35-237 tmp]$ eksctl delete cluster --name my-cluster
2024-09-21 10:37:26 [ℹ]  deleting EKS cluster "my-cluster"
2024-09-21 10:37:26 [ℹ]  will drain 0 unmanaged nodegroup(s) in cluster "my-cluster"
2024-09-21 10:37:26 [ℹ]  starting parallel draining, max in-flight of 1
2024-09-21 10:37:26 [✖]  failed to acquire semaphore while waiting for all routines to finish: context canceled
2024-09-21 10:37:26 [ℹ]  deleted 0 Fargate profile(s)
2024-09-21 10:37:26 [✔]  kubeconfig has been updated
2024-09-21 10:37:26 [ℹ]  cleaning up AWS load balancers created by Kubernetes objects of Kind Service or Ingress
2024-09-21 10:37:27 [ℹ]  
2 sequential tasks: { delete nodegroup "linux-nodes", delete cluster control plane "my-cluster" [async] 
}
2024-09-21 10:37:27 [ℹ]  will delete stack "eksctl-my-cluster-nodegroup-linux-nodes"
2024-09-21 10:37:27 [ℹ]  waiting for stack "eksctl-my-cluster-nodegroup-linux-nodes" to get deleted
2024-09-21 10:37:27 [ℹ]  waiting for CloudFormation stack "eksctl-my-cluster-nodegroup-linux-nodes"
2024-09-21 10:37:57 [ℹ]  waiting for CloudFormation stack "eksctl-my-cluster-nodegroup-linux-nodes"
2024-09-21 10:38:40 [ℹ]  waiting for CloudFormation stack "eksctl-my-cluster-nodegroup-linux-nodes"
2024-09-21 10:39:59 [ℹ]  waiting for CloudFormation stack "eksctl-my-cluster-nodegroup-linux-nodes"
2024-09-21 10:41:27 [ℹ]  waiting for CloudFormation stack "eksctl-my-cluster-nodegroup-linux-nodes"
2024-09-21 10:43:06 [ℹ]  waiting for CloudFormation stack "eksctl-my-cluster-nodegroup-linux-nodes"